代码: pytorch版本 https://github.com/ACheun9/Pytorch-implementation-of-Mobile-Former

博客: https://mp.weixin.qq.com/s/yo5KmB2Y7t2R4jiOKI87HQ

视频讲解: https://www.bilibili.com/video/BV16Q4y1U7Rz?p=1

知识点补充：

动态relu: https://blog.csdn.net/weixin_42096202/article/details/109727151 这种效果提升较大

1.特征的融合在bottleneck的瓶颈部位，这时的channel数目少，结构紧凑，融合信息稳定。channel数目上升融合后又要降维，会损失一部分信息。

2.网络轻量，可用于目标检测

3.MobileNet和Transformer的并行设计，利用了MobileNet在局部处理和Transformer在全局交互方面的优势。

4.Mobile-Former中的Transformer包含非常少的随机初始化的token导致计算成本低。

5.论文中公式提到的线性映射通过分头降低了参数，双向桥的过程采用多头注意力容易被忽视

6.局限性:

首先，由于Mobile，Former和bridge都有各自的参数，因此并行设计在参数共享方面效率不高；虽然Former由于token数量少，计算效率高，但它并不节省参数的数量。

其次，在执行ImageNet分类任务时，Mobile-Former在分类头(2个全连接层)中消耗了很多参数。例如，Mobile-Former-294M在分类头中花费了40% (11.4M中的4.6M)参数。当从图像分类切换到目标检测任务时，由于去掉了分类头，模型大小问题得到了缓解。
